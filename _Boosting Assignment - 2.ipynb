{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6788af0a-5ef4-4fe3-aa0e-1acfc3777fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer ## HAndle Missing Values\n",
    "from sklearn.preprocessing import StandardScaler ## Feature Scaling\n",
    "from sklearn.preprocessing import OneHotEncoder ## categorical to numerical\n",
    "from sklearn.compose import ColumnTransformer # connecting pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bd6cfc-0305-4610-8ab6-5f939e50a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('tips.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec87358-f45c-429d-ad0b-0b2289bef511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "270e96d3-94a8-4630-9609-d8c9ecccf5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46ff404-374a-477a-8ed1-24a69a683084",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(labels='total_bill',axis=1)\n",
    "y=df['total_bill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc857b1-bd32-4c8f-9c87-6de804a75820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>5.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1.75</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tip     sex smoker   day    time  size\n",
       "0    1.01  Female     No   Sun  Dinner     2\n",
       "1    1.66    Male     No   Sun  Dinner     3\n",
       "2    3.50    Male     No   Sun  Dinner     3\n",
       "3    3.31    Male     No   Sun  Dinner     2\n",
       "4    3.61  Female     No   Sun  Dinner     4\n",
       "..    ...     ...    ...   ...     ...   ...\n",
       "239  5.92    Male     No   Sat  Dinner     3\n",
       "240  2.00  Female    Yes   Sat  Dinner     2\n",
       "241  2.00    Male    Yes   Sat  Dinner     2\n",
       "242  1.75    Male     No   Sat  Dinner     2\n",
       "243  3.00  Female     No  Thur  Dinner     2\n",
       "\n",
       "[244 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44f218df-fcd2-42dc-9493-181af2523bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      16.99\n",
       "1      10.34\n",
       "2      21.01\n",
       "3      23.68\n",
       "4      24.59\n",
       "       ...  \n",
       "239    29.03\n",
       "240    27.18\n",
       "241    22.67\n",
       "242    17.82\n",
       "243    18.78\n",
       "Name: total_bill, Length: 244, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be0785-0819-4065-91ff-97df714b57cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "991247a8-adaa-482a-876f-66e794a41d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((183, 6), (61, 6))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=10)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af685bf2-39e4-4f28-9ee6-9d64ee981189",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['sex', 'smoker', 'day','time']\n",
    "num_cols=[ 'tip','size']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f099d9b4-e7b5-4cfe-b469-7dbf7dc189a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numercial pipeline\n",
    "\n",
    "num_pipeline=Pipeline(\n",
    "     steps=[\n",
    "     ('imputer',SimpleImputer(strategy='median')),\n",
    "     ('scaler', StandardScaler())\n",
    "     \n",
    "     \n",
    "     ]\n",
    "\n",
    ")\n",
    "\n",
    "# categorical pipeline\n",
    "\n",
    "cat_pipeline=Pipeline(\n",
    "     steps=[\n",
    "     ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "     ('encoder', OneHotEncoder())\n",
    "     \n",
    "     \n",
    "     ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5777ea17-936d-4553-a753-f12ef4e38d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=ColumnTransformer([\n",
    "    \n",
    "    ('num_pipeline',num_pipeline,num_cols),\n",
    "    ('cat_pipeline',cat_pipeline,cat_cols)\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5acef5fd-3fc3-407c-bd15-374bcfc8b8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;tip&#x27;, &#x27;size&#x27;]),\n",
       "                                (&#x27;cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;, OneHotEncoder())]),\n",
       "                                 [&#x27;sex&#x27;, &#x27;smoker&#x27;, &#x27;day&#x27;, &#x27;time&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;tip&#x27;, &#x27;size&#x27;]),\n",
       "                                (&#x27;cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;, OneHotEncoder())]),\n",
       "                                 [&#x27;sex&#x27;, &#x27;smoker&#x27;, &#x27;day&#x27;, &#x27;time&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;tip&#x27;, &#x27;size&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sex&#x27;, &#x27;smoker&#x27;, &#x27;day&#x27;, &#x27;time&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['tip', 'size']),\n",
       "                                ('cat_pipeline',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('encoder', OneHotEncoder())]),\n",
       "                                 ['sex', 'smoker', 'day', 'time'])])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7724d95a-0cd9-4966-b373-db4b8986e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=preprocessor.fit_transform(X_train)\n",
    "X_test=preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df35162b-f41f-4105-aa8d-7a7745e0059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "815deb95-28fb-42e1-bb7f-3e1da41a5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    'Gradient Boost':GradientBoostingRegressor(),\n",
    "    'Random Forest Regressor':RandomForestRegressor()\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9261d9d-3373-43ed-8e39-59f5ca94161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58ac4ffb-edf1-459a-b8a1-574bc2b52332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train,y_train,X_test,y_test,models):\n",
    "\n",
    "    report = {}\n",
    "    for i in range(len(models)):\n",
    "        model = list(models.values())[i]\n",
    "        # Train model\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "        # Predict Testing data\n",
    "        y_test_pred =model.predict(X_test)\n",
    "\n",
    "        # Get accuracy for test data prediction\n",
    "\n",
    "        test_model_score = r2_score(y_test,y_test_pred)\n",
    "\n",
    "        report[list(models.keys())[i]] =  test_model_score\n",
    "\n",
    "\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6b0fbe2-69b0-43da-a016-ca6f3978251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gradient Boost': 0.3708544822994033,\n",
       " 'Random Forest Regressor': 0.44705902350652615}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(X_train,y_train,X_test,y_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e1aa8f0-4db8-4180-8f64-5af7af3a4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad=GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9569426-4bd9-442a-ba38-fe8d6670ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'loss':['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "    'learning_rate':[0.1,0.01,1],\n",
    "    'criterion':['friedman_mse', 'squared_error'],\n",
    "    'n_estimators':[100,150,200]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d068df6d-cb59-4aad-8cc3-4b4f94e5293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a95a1a55-57f9-4694-9d3d-82d54a7c614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=GridSearchCV(grad,param_grid=params,cv=6,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9288b91-2823-42bf-829c-20f85b2ed1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 72 candidates, totalling 432 fits\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.228 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.396 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.645 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.554 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.560 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.449 total time=   0.1s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.180 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.421 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.621 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.546 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.522 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.438 total time=   0.1s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.184 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.412 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.566 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.538 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.513 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.379 total time=   0.1s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.155 total time=   0.2s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.390 total time=   0.2s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.527 total time=   0.2s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.514 total time=   0.2s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.528 total time=   0.2s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.470 total time=   0.2s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.184 total time=   0.3s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.396 total time=   0.3s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.432 total time=   0.3s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.531 total time=   0.3s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.515 total time=   0.3s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.472 total time=   0.3s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.174 total time=   0.4s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.393 total time=   0.4s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.521 total time=   0.4s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.446 total time=   0.4s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.484 total time=   0.4s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.442 total time=   0.4s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.152 total time=   0.3s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.470 total time=   0.3s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.650 total time=   0.3s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.457 total time=   0.4s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.531 total time=   0.3s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.414 total time=   0.3s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.146 total time=   0.5s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.521 total time=   0.5s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.630 total time=   0.5s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.475 total time=   0.5s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.504 total time=   0.5s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.400 total time=   0.5s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.120 total time=   0.7s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.560 total time=   0.7s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.599 total time=   0.7s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.478 total time=   0.7s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.503 total time=   0.7s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.450 total time=   0.7s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=100;, score=-0.256 total time=   0.2s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=100;, score=-0.907 total time=   0.2s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=100;, score=0.129 total time=   0.2s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=100;, score=0.235 total time=   0.2s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=100;, score=-0.022 total time=   0.2s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=100;, score=-0.241 total time=   0.2s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=150;, score=-0.256 total time=   0.3s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=150;, score=-0.923 total time=   0.3s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=150;, score=0.119 total time=   0.3s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=150;, score=0.215 total time=   0.3s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=150;, score=-0.067 total time=   0.4s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=150;, score=-0.400 total time=   0.3s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=200;, score=-0.230 total time=   0.4s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=200;, score=-0.694 total time=   0.4s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=200;, score=0.188 total time=   0.4s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=200;, score=0.280 total time=   0.4s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=200;, score=-0.050 total time=   0.5s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, n_estimators=200;, score=-0.279 total time=   0.5s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.293 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.334 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.516 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.492 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.449 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.402 total time=   0.1s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.283 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.356 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.585 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.544 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.533 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.470 total time=   0.1s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.262 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.371 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.605 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.553 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.559 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.479 total time=   0.1s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.169 total time=   0.3s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.330 total time=   0.3s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.317 total time=   0.3s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.424 total time=   0.3s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.388 total time=   0.3s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.470 total time=   0.3s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.211 total time=   0.4s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.397 total time=   0.4s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.388 total time=   0.4s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.490 total time=   0.4s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.430 total time=   0.4s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.515 total time=   0.4s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.225 total time=   0.6s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.414 total time=   0.5s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.395 total time=   0.6s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.497 total time=   0.6s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.440 total time=   0.6s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.513 total time=   0.6s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.226 total time=   0.4s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.362 total time=   0.4s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.403 total time=   0.4s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.428 total time=   0.4s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.437 total time=   0.4s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.370 total time=   0.4s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.234 total time=   0.5s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.399 total time=   0.5s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.477 total time=   0.6s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.488 total time=   0.5s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.497 total time=   0.5s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.409 total time=   0.5s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.228 total time=   0.7s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.392 total time=   0.7s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.517 total time=   0.7s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.503 total time=   0.7s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.520 total time=   0.7s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.436 total time=   0.7s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-0.817 total time=   0.2s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-2.335 total time=   0.2s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-0.643 total time=   0.3s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-0.227 total time=   0.3s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-1.220 total time=   0.2s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-1.298 total time=   0.2s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-0.647 total time=   0.3s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-1.940 total time=   0.3s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-0.391 total time=   0.4s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-0.122 total time=   0.4s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-0.842 total time=   0.4s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-1.028 total time=   0.3s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.569 total time=   0.5s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-1.711 total time=   0.4s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.195 total time=   0.5s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.046 total time=   0.5s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.619 total time=   0.5s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.815 total time=   0.5s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=100;, score=-0.183 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.037 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.012 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.300 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.289 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.131 total time=   0.1s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=150;, score=-0.188 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=150;, score=-0.009 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=150;, score=-0.060 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=150;, score=0.263 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=150;, score=0.246 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=150;, score=0.102 total time=   0.1s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=200;, score=-0.183 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=200;, score=-0.065 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=200;, score=-0.167 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=200;, score=0.254 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=200;, score=0.243 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=squared_error, n_estimators=200;, score=0.113 total time=   0.1s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.164 total time=   0.3s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.045 total time=   0.2s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.573 total time=   0.2s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.353 total time=   0.2s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.253 total time=   0.2s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.189 total time=   0.2s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.198 total time=   0.3s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.435 total time=   0.3s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.607 total time=   0.3s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.340 total time=   0.3s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.415 total time=   0.3s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.243 total time=   0.3s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.198 total time=   0.4s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.416 total time=   0.4s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.237 total time=   0.4s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.322 total time=   0.4s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.478 total time=   0.5s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.189 total time=   0.4s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=100;, score=-0.098 total time=   0.3s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=100;, score=-0.017 total time=   0.3s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=100;, score=0.079 total time=   0.3s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=100;, score=0.388 total time=   0.3s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=100;, score=0.207 total time=   0.3s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=100;, score=-0.128 total time=   0.3s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=150;, score=-0.115 total time=   0.5s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=150;, score=0.030 total time=   0.5s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=150;, score=0.032 total time=   0.5s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=150;, score=0.386 total time=   0.5s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=150;, score=0.186 total time=   0.5s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=150;, score=-0.205 total time=   0.5s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=200;, score=-0.121 total time=   0.7s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=200;, score=-0.112 total time=   0.7s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=200;, score=0.146 total time=   0.7s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=200;, score=0.392 total time=   0.7s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=200;, score=0.179 total time=   0.7s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=huber, n_estimators=200;, score=-0.078 total time=   0.7s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=100;, score=-1.094 total time=   0.1s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=100;, score=-0.743 total time=   0.1s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=100;, score=-0.002 total time=   0.1s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=100;, score=-0.377 total time=   0.1s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=100;, score=-0.072 total time=   0.1s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=100;, score=-0.248 total time=   0.2s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=150;, score=-1.040 total time=   0.2s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.659 total time=   0.3s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.001 total time=   0.2s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.377 total time=   0.2s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.072 total time=   0.2s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.331 total time=   0.2s\n",
      "[CV 1/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=200;, score=-1.076 total time=   0.2s\n",
      "[CV 2/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=200;, score=-0.659 total time=   0.4s\n",
      "[CV 3/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=200;, score=-0.002 total time=   0.2s\n",
      "[CV 4/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=200;, score=-0.377 total time=   0.2s\n",
      "[CV 5/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=200;, score=0.060 total time=   0.2s\n",
      "[CV 6/6] END criterion=friedman_mse, learning_rate=1, loss=quantile, n_estimators=200;, score=-0.244 total time=   0.4s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.227 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.419 total time=   0.1s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.645 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.552 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.501 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=100;, score=0.451 total time=   0.1s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.182 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.411 total time=   0.1s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.618 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.549 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.519 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=150;, score=0.432 total time=   0.1s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.183 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.415 total time=   0.1s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.565 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.542 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.503 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=squared_error, n_estimators=200;, score=0.382 total time=   0.1s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.166 total time=   0.2s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.388 total time=   0.2s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.505 total time=   0.2s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.533 total time=   0.2s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.542 total time=   0.2s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=100;, score=0.523 total time=   0.2s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.157 total time=   0.3s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.470 total time=   0.3s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.498 total time=   0.3s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.458 total time=   0.3s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.509 total time=   0.3s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=150;, score=0.420 total time=   0.3s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.178 total time=   0.4s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.398 total time=   0.4s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.464 total time=   0.4s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.529 total time=   0.4s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.513 total time=   0.4s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, n_estimators=200;, score=0.482 total time=   0.4s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.116 total time=   0.3s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.474 total time=   0.3s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.646 total time=   0.3s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.483 total time=   0.4s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.525 total time=   0.3s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=100;, score=0.450 total time=   0.4s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.138 total time=   0.5s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.515 total time=   0.5s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.638 total time=   0.5s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.469 total time=   0.5s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.529 total time=   0.5s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=150;, score=0.411 total time=   0.5s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.117 total time=   0.7s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.566 total time=   0.7s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.601 total time=   0.7s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.461 total time=   0.7s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.510 total time=   0.7s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=huber, n_estimators=200;, score=0.430 total time=   0.7s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=100;, score=-0.256 total time=   0.2s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=100;, score=-0.875 total time=   0.2s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=100;, score=0.147 total time=   0.2s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=100;, score=0.255 total time=   0.2s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=100;, score=-0.102 total time=   0.3s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=100;, score=-0.250 total time=   0.3s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=150;, score=-0.350 total time=   0.3s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=150;, score=-0.789 total time=   0.3s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=150;, score=0.107 total time=   0.3s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=150;, score=0.254 total time=   0.3s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=150;, score=0.058 total time=   0.4s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=150;, score=-0.308 total time=   0.3s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=200;, score=-0.277 total time=   0.5s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=200;, score=-0.586 total time=   0.4s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=200;, score=0.174 total time=   0.4s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=200;, score=0.325 total time=   0.4s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=200;, score=-0.040 total time=   0.5s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.1, loss=quantile, n_estimators=200;, score=-0.294 total time=   0.5s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.293 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.334 total time=   0.1s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.516 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.492 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.449 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=100;, score=0.402 total time=   0.1s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.283 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.356 total time=   0.1s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.585 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.544 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.533 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=150;, score=0.470 total time=   0.1s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.262 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.371 total time=   0.1s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.604 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.553 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.559 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=squared_error, n_estimators=200;, score=0.479 total time=   0.1s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.169 total time=   0.3s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.358 total time=   0.3s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.326 total time=   0.3s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.421 total time=   0.3s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.386 total time=   0.3s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=100;, score=0.468 total time=   0.3s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.211 total time=   0.4s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.401 total time=   0.4s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.387 total time=   0.4s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.488 total time=   0.4s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.425 total time=   0.4s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=150;, score=0.510 total time=   0.4s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.225 total time=   0.6s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.475 total time=   0.6s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.406 total time=   0.6s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.497 total time=   0.6s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.442 total time=   0.6s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, n_estimators=200;, score=0.499 total time=   0.6s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.226 total time=   0.4s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.362 total time=   0.4s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.403 total time=   0.4s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.428 total time=   0.4s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.437 total time=   0.4s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=100;, score=0.370 total time=   0.4s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.234 total time=   0.5s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.399 total time=   0.5s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.477 total time=   0.5s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.488 total time=   0.5s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.497 total time=   0.5s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=150;, score=0.409 total time=   0.5s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.229 total time=   0.7s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.391 total time=   0.7s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.517 total time=   0.7s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.503 total time=   0.7s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.518 total time=   0.7s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=huber, n_estimators=200;, score=0.433 total time=   0.7s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-0.816 total time=   0.2s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-2.349 total time=   0.2s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-0.642 total time=   0.3s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-0.229 total time=   0.3s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-1.218 total time=   0.2s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=100;, score=-1.303 total time=   0.2s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-0.636 total time=   0.3s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-1.936 total time=   0.3s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-0.406 total time=   0.4s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-0.124 total time=   0.4s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-0.823 total time=   0.4s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=150;, score=-1.036 total time=   0.3s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.546 total time=   0.5s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-1.707 total time=   0.4s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.202 total time=   0.5s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.051 total time=   0.5s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.638 total time=   0.5s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=0.01, loss=quantile, n_estimators=200;, score=-0.820 total time=   0.5s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=100;, score=-0.185 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.078 total time=   0.1s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.026 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.296 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.201 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=100;, score=0.064 total time=   0.1s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=150;, score=-0.190 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=150;, score=-0.033 total time=   0.1s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=150;, score=-0.064 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=150;, score=0.223 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=150;, score=0.216 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=150;, score=0.094 total time=   0.1s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=200;, score=-0.180 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=200;, score=-0.116 total time=   0.1s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=200;, score=-0.166 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=200;, score=0.230 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=200;, score=0.198 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=squared_error, n_estimators=200;, score=0.064 total time=   0.1s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.192 total time=   0.2s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.194 total time=   0.2s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.477 total time=   0.2s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.382 total time=   0.2s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.229 total time=   0.2s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=100;, score=0.189 total time=   0.2s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.221 total time=   0.3s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.139 total time=   0.3s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.605 total time=   0.3s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.335 total time=   0.3s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.413 total time=   0.4s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=150;, score=0.243 total time=   0.3s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.114 total time=   0.5s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.294 total time=   0.4s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.565 total time=   0.4s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.335 total time=   0.4s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.460 total time=   0.4s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=absolute_error, n_estimators=200;, score=0.189 total time=   0.4s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=100;, score=-0.088 total time=   0.3s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=100;, score=-0.048 total time=   0.3s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=100;, score=0.119 total time=   0.4s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=100;, score=0.397 total time=   0.3s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=100;, score=0.217 total time=   0.4s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=100;, score=-0.017 total time=   0.3s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=150;, score=-0.110 total time=   0.5s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=150;, score=-0.012 total time=   0.5s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=150;, score=0.211 total time=   0.5s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=150;, score=0.392 total time=   0.5s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=150;, score=0.426 total time=   0.5s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=150;, score=-0.074 total time=   0.5s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=200;, score=-0.154 total time=   0.7s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=200;, score=0.026 total time=   0.7s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=200;, score=0.156 total time=   0.7s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=200;, score=0.395 total time=   0.7s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=200;, score=0.185 total time=   0.7s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=huber, n_estimators=200;, score=-0.099 total time=   0.7s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=100;, score=-1.040 total time=   0.1s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=100;, score=-0.659 total time=   0.2s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=100;, score=-0.001 total time=   0.1s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=100;, score=-0.377 total time=   0.1s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=100;, score=0.084 total time=   0.1s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=100;, score=-0.244 total time=   0.2s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.947 total time=   0.2s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.723 total time=   0.2s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.001 total time=   0.2s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.253 total time=   0.2s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.072 total time=   0.2s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=150;, score=-0.236 total time=   0.2s\n",
      "[CV 1/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=200;, score=-0.646 total time=   0.2s\n",
      "[CV 2/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=200;, score=-0.659 total time=   0.4s\n",
      "[CV 3/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=200;, score=-0.002 total time=   0.2s\n",
      "[CV 4/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=200;, score=-0.376 total time=   0.2s\n",
      "[CV 5/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=200;, score=0.022 total time=   0.2s\n",
      "[CV 6/6] END criterion=squared_error, learning_rate=1, loss=quantile, n_estimators=200;, score=-0.210 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=6, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;, &#x27;squared_error&#x27;],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 0.01, 1],\n",
       "                         &#x27;loss&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;, &#x27;huber&#x27;,\n",
       "                                  &#x27;quantile&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 150, 200]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=6, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;, &#x27;squared_error&#x27;],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 0.01, 1],\n",
       "                         &#x27;loss&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;, &#x27;huber&#x27;,\n",
       "                                  &#x27;quantile&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 150, 200]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=6, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'criterion': ['friedman_mse', 'squared_error'],\n",
       "                         'learning_rate': [0.1, 0.01, 1],\n",
       "                         'loss': ['squared_error', 'absolute_error', 'huber',\n",
       "                                  'quantile'],\n",
       "                         'n_estimators': [100, 150, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a198bfbe-4571-4672-a54d-54d46254b70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'squared_error',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aef7e977-9943-47ea-bfa6-c732333633aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47206951762350086"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbd236ce-34fb-4055-9220-0b711498b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c3a21d5-f80d-4bd1-ba72-1cd44bdbdbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3732289807250976"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f321c81-4e18-4b91-90c7-5bbd56de1ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
