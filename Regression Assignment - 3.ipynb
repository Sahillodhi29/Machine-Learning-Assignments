{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f577b-8b9a-44fd-ba6d-30871c32da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?'''\n",
    "'''\n",
    "Ridge Regression is also known as l2 regularization \n",
    "and it helps to prevent overfiiting in model \n",
    "\n",
    "it uses a penalty term which has lambda and summation of squares of slopes\n",
    "\n",
    "In Ridge Regression, the L2 penalty term encourages the model to shrink the coefficients toward zero '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866238e9-3a72-4496-9a88-274f8958b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q2. What are the assumptions of Ridge Regression?'''\n",
    "'''\n",
    "1. there is a linear relationship between input and output features.\n",
    "2. apropriate choice of regularization paramter lambda. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a756a-1092-4f76-9dcd-d41c0bc772df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?'''\n",
    "'''\n",
    "the optimal value of lambda may vary depending on the specific dataset and the goals of the analysis.\n",
    "Cross-validation is generally considered a robust and widely applicable method for model selection. \n",
    "The scikit-learn library in Python, for example, provides tools for conducting cross-validated grid searches\n",
    "for hyperparameter tuning in Ridge Regression. '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf9dd4-9f62-4b6d-9acb-2f98708ccb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q4. Can Ridge Regression be used for feature selection? If yes, how?'''\n",
    "'''\n",
    "yes Ridge REgression can be used for feature selection to some extent. as it introduces a penalty term to \n",
    "the MSE and it helps for the shrinkage of the coefficients towards zero but rarely forces them exactly to zero.\n",
    "However, the degree of shrinkage depends on the strength of the regularization parameter lambda\n",
    "\n",
    "hence by inceasing the value we can make the cofficient decreases to some negligible values and hence we select features .'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
